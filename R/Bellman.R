  #' Compute Bellman values at step i from step i+1
  #'
  #' @param Data_week A "data.table" generated in Grid_Matrix code
  #' that contains:
  #'  * states Numeric. All the water values that can be set, listed in
  #'   decreasing order.
  #'  * value_inflow Numeric. Inflow values for each Monte-Carlo year.
  #'  * Rewards for each simulation value and each Monte-Carlo year.
  #'  * level_high Numeric. Highest possible reservoir value.
  #'  * level_low Numeric. Lowest possible reservoir value.
  #'  * states_next List of vectors enumerating all reachable states
  #' @param decision_space Simulation constraints values
  #' @param next_week_values_l Numeric. Bellman values at step i+1.
  #' @param E_max Numeric of length 1. Maximum energy that can be generated by
  #'   hydro storage over one step of time.
  #' @param P_max Numeric of length 1. Maximum energy that can be pumped to
  #' reservoir over one step of time.
  #' @param method Character. Perform mean of grids algorithm or grid of means algorithm or
  #'  grid of quantile algorithm.
  #' @param q_ratio numeric in [0,1]. the probability used in quantile algorithm.
  #' @param counter Numeric of length 1. number of the week in calculation.
  #' @param correct_outliers If TRUE, outliers in Bellman values are replaced by spline
  #'   interpolations. Defaults to FALSE.
  #' @param stop_rate the percent from which the calculation stop. for example
  #' \code{stop_rate=5} means the calculation stop if there is a week with less then
  #' 5\% accessibles states.
  #' @param mcyears Vector. Monte Carlo years
  #' @param states_steps Numeric. Discretization step of reservoir.
  #' @param debugger_feas open debug mode in case there is an error of no accessible states
  #' @param niveau_max Level max of the reservoir
  #' @param penalty_level_low Penalty for violating the bottom rule curve, comparable to the unsupplied energy
  #' @param penalty_level_high Penalty for violating the top rule curve, comparable to the spilled energy
  #'
  #' @return a \code{data.table} like Data_week with the Bellman values
  #' @importFrom stats ave quantile
  #' @export


  Bellman <- function(Data_week,next_week_values_l,decision_space,E_max,P_max=0,
                      method,mcyears,correct_outliers=FALSE,q_ratio=0.75,
                      counter,
                      stop_rate=5,debugger_feas=F,niveau_max,
                      states_steps,penalty_level_low,penalty_level_high){


    decision_space <- unlist(decision_space, use.names = FALSE)
    decision_space <- round(decision_space)
    alpha <- getOption(x = "watervalues.alpha", default = 0.0001)
    decimals <- getOption(x = "watervalues.decimals", default = 3)

    level_high <- Data_week$level_high[1]
    level_low <- Data_week$level_low[1]

    states_next <- Data_week$states_next[[1]]
    states_next <- unlist(states_next, use.names = FALSE)

    f_reward_year <- get_reward_interpolation(Data_week,decision_space,mcyears)

    f_next_value <- get_bellman_values_interpolation(Data_week,next_week_values_l,mcyears)

    df_SDP <- build_all_possible_decisions(Data_week,decision_space,f_next_value,
                                           mcyears,level_high,level_low,E_max,P_max,
                                           next_week_values_l,niveau_max)

    # find maximum for each year and each state of reward plus next bellman value
    df_SDP <- df_SDP %>%
      mutate(gain=mapply(function(y,x)f_reward_year[[which(y==mcyears)]](x), years, control),
             penalty_low = if_else(next_state<=level_low,penalty_level_low*(next_state-level_low),0),
             penalty_high = if_else(next_state>=level_high,penalty_level_high*(level_high-next_state),0),
             sum=gain+next_value+penalty_low+penalty_high) %>%
      group_by(years,states) %>%
      slice(which.max(sum)) %>%
      select(-c("value_node","transition","transition_reward",
                "next_bellman_value")) %>%
      rename("value_node"="sum","transition"="control","transition_reward"="gain",
             "next_bellman_value"="next_value")

    # reorder df_SDP as Data_week
    Data_week <- left_join(Data_week[,-c("value_node","transition","transition_reward",
                                         "next_bellman_value")],df_SDP[,c("years","states","value_node","transition",
                                                                          "transition_reward","next_bellman_value")],
                           by=c("years","states"))


    #------ mean-grid method---------

    if (method == "mean-grid") {
      if (correct_outliers) {
        Data_week[, value_node := correct_outliers(value_node), by = years]
      }
      return(Data_week)
    }

    #------ grid-mean method---------

    if(method=="grid-mean"){
      if (correct_outliers) {
        Data_week[, value_node := correct_outliers(value_node)]
      }
      Data_week$value_node <- stats::ave(Data_week$value_node, Data_week$statesid, FUN=function(x) mean_finite(x))

      return(Data_week)
    }

    if (method=="quantile"){
      if (correct_outliers) {
        Data_week[, value_node := correct_outliers(value_node)]
      }

      Data_week$value_node <- stats::ave(Data_week$value_node, Data_week$statesid, FUN=function(x) stats::quantile(x, q_ratio,na.rm =T))


      return(Data_week)
    }

    return(Data_week)

}

  #' Compute Bellman values at step i from step i+1 (version used in parallel computing)
  #'
  #' @param Data_week A "data.table" generated in Grid_Matrix code
  #' that contains:
  #'  * states Numeric. All the water values that can be set, listed in
  #'   decreasing order.
  #'  * value_inflow Numeric. Inflow values for each Monte-Carlo year.
  #'  * Rewards for each simulation value and each Monte-Carlo year.
  #'  * level_high Numeric. Highest possible reservoir value.
  #'  * level_low Numeric. Lowest possible reservoir value.
  #'  * states_next List of vectors enumerating all reachable states
  #' @param i the row number of the point to calculate her bellman value.
  #' @param decision_space Simulation constraints values
  #' @param next_week_values_l Numeric. Bellman values at step i+1.
  #' @param niveau_max Numeric of length 1. Reservoir capacity.
  #' @param E_max Numeric of length 1. Maximum energy that can be generated by
  #'   hydro storage over one step of time.
  #' @param P_max Numeric of length 1. Maximum energy that can be pumped to
  #' reservoir over one step of time.
  #' @param na_rm Boolean. Remove NAs
  #' @param max_mcyear Numeric of length 1. Number of Monte-Carlo year
  #'  used in simulations
  #' @param alpha maximum tolerance.
  #' @param decimals number of decimals.
  #' @return a \code{data.table} like Data_week with the Bellman values
  #' @importFrom stats ave quantile
  #' @export

  bellman_parallel_value <- function(Data_week,i,next_week_values_l,max_mcyear,
                                     E_max,P_max,niveau_max,na_rm
                                     ,decision_space,alpha,decimals){


  #init
  {
    states <- Data_week$states[i]
    statesID <- Data_week$statesid[i]
    level_high <- Data_week$level_high[i]
    level_low <- Data_week$level_low[i]
    value_inflow <- Data_week$hydroStorage[i]
    reward <- Data_week$reward[[i]]
    states_next <- Data_week$states_next[[i]]


    value_reward <- unlist(reward, use.names = FALSE)
    states_next <- unlist(states_next, use.names = FALSE)


    next_week_values <- next_week_value(next_week_values_l,max_mcyear,i)

  }



  #eliminate non accessible states
  if (states > round(level_high, decimals) - alpha) {
    return( -Inf)

  }
  if (states < round(level_low, decimals) + alpha) {
    return(-Inf)

  }

    # max possible decision --------

    largest_decisions <- largest_decisions(states,value_inflow,niveau_max,E_max,P_max)

    largest_turb <-largest_decisions$largest_turb

    largest_pump <- largest_decisions$largest_pump



    # the decisions that respect the max possible decision used in simulation constraints

    decisions_current <- check_largest_decisions(decision_space,largest_decisions,alpha)


    # Possible next states
    next_states <- states_next[states_next >= (states - E_max + value_inflow) & states_next <= (states + P_max + value_inflow + alpha) ]



    # Turbaned energy per transition

    turbined_energy <- turbined_energy(states,next_states,value_inflow,decisions_current,largest_decisions)

    #add element to decisions_current to cover all needed information in the future
    decisions_cover <-decisions_cover(turbined_energy,decisions_current)

    # List of accessible Rewards

    step_reward <- accessible_rewards(decisions_cover,decision_space,value_reward)

    provisional_steps <- step_reward$steps
    provisional_reward_line <- step_reward$rewards


    decisions <- generate_decisions(turbined_energy,decisions_cover,E_max,P_max)



    decision_rewards <- generate_decisions_rewards(decisions,step_reward,alpha)


    # respect the rule graph constraints

    decisions <-  rule_cs_check(decisions,states,value_inflow,level_high,level_low,alpha)


    # Bellman calculator
    Bellman_values <- bellman_calculator(decisions,next_week_values,decision_rewards,states,value_inflow,niveau_max,states_next,alpha,na_rm)







  return(max(Bellman_values, na.rm = TRUE))

  }







% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Grid_Matrix.R
\name{Grid_Matrix}
\alias{Grid_Matrix}
\title{Compute Bellman values}
\usage{
Grid_Matrix(
  area,
  simulation_names,
  expansion,
  reward_db = NULL,
  simulation_values = NULL,
  nb_cycle = 1L,
  mcyears = NULL,
  week_53 = 0,
  states_step_ratio = 0.01,
  reservoir_capacity = NULL,
  cvar_value = 1,
  opts,
  shiny = F,
  until_convergence = F,
  convergence_rate = 0.9,
  convergence_criteria = 1,
  cycle_limit = 10,
  pumping = F,
  efficiency = 1,
  correct_concavity = FALSE,
  correct_monotony = FALSE,
  penalty_low = 3000,
  penalty_high = 3000,
  method_old = F,
  possible_controls = NULL,
  max_hydro_hourly = NULL,
  max_hydro_weekly = NULL,
  force_final_level = F,
  final_level = NULL,
  penalty_final_level_low = NULL,
  penalty_final_level_high = NULL
)
}
\arguments{
\item{area}{Character. The Antares area concerned by water values computation.}

\item{simulation_names}{Vector of character. List of simulations names to use to compute reward.
Correspond to \code{simulation_names} output of \code{runWaterValuesSimulation()}.}

\item{expansion}{Binary. True if mode expansion (ie linear relaxation) of Antares is used to run simulations, argument passed to \code{\link[antaresEditObject]{runSimulation}}.
It is recommended to use mode expansion, it will be faster (only one iteration is done) and results will be smoother as the cost result will correspond to the linear relaxation of the problem.}

\item{reward_db}{Reward functions generated by the function \code{get_Reward()} if already computed.}

\item{simulation_values}{A \code{dplyr::tibble()} with columns \code{"week"}, \code{"sim"}, \code{"u"} and \code{"mcYear"} (optional) that gives constraint values per week (and per scenario) used in each simulation.
Correspond to \code{simulation_values} output of \code{runWaterValuesSimulation()}.}

\item{nb_cycle}{Integer. Number of times to run dynamic programming. Used to avoid dependency on final Bellman values.}

\item{mcyears}{Vector of integer. Monte Carlo years used to compute water values.}

\item{week_53}{Double or vector of doubles. Final bellman values used at the end of week 52 for the first cycle performed.}

\item{states_step_ratio}{Double. Discretization ratio to generate steps levels
between the reservoir capacity and zero for which Bellman values are computed.}

\item{reservoir_capacity}{Double. Reservoir capacity for the given area in MWh given by \code{get_reservoir_capacity()}.}

\item{cvar_value}{Double from 0 to 1. The probability used in cvar method.}

\item{opts}{List of study parameters returned by the function \code{antaresRead::setSimulationPath(simulation="input")} in input mode.}

\item{shiny}{Binary. \code{TRUE} if the function is called from \code{shiny_water_values()}.}

\item{convergence_rate}{Double from 0 to 1. Define the convergence level if \code{until_convergence=TRUE}.
\code{1} means all values should have converged (ie identical water values between current cycle and the last one) and \code{0} means no convergence is needed to stop.}

\item{convergence_criteria}{Double. Used if \code{until_convergence=TRUE}. Thereshold to consider that two different water values are identical.}

\item{cycle_limit}{Integer. Used if \code{until_convergence=TRUE}. Maximum cycles to perform.}

\item{pumping}{Boolean. True to take into account the pumping capacity.}

\item{efficiency}{Double between 0 and 1. Pumping efficiency ratio. Get it with \code{getPumpEfficiency()}.}

\item{correct_concavity}{Binary argument (default to \code{FALSE}). \code{TRUE} to correct concavity of Bellman values.}

\item{correct_monotony}{Binary. True to correct monotony of rewards if \code{method_old = TRUE}.}

\item{penalty_low}{Double. Penalty for violating the bottom rule curve, comparable to the unsupplied energy cost.}

\item{penalty_high}{Double. Penalty for violating the top rule curve, comparable to the spilled energy cost.}

\item{method_old}{Binary. Method to build reward function.}

\item{possible_controls}{If \code{method_old=FALSE}, controls for which to compute reward, generated by \code{constraint_generator()}.}

\item{max_hydro_hourly}{Maximum hourly pumping and generating power generated by the function \code{get_max_hydro()} with \code{timeStep="hourly"}.}

\item{max_hydro_weekly}{Maximum weekly pumping and generating power generated by the function \code{get_max_hydro()} with \code{timeStep="hourly"}.}

\item{force_final_level}{Binary. Whether final level should be constrained.}

\item{final_level}{Double. Final level (in percent between 0 and 100) if final level is constrained. If you want initial level, use \code{get_initial_level()}.}

\item{penalty_final_level_low}{Double. Penalties for both bottom rule curve to constrain final level.}

\item{penalty_final_level_high}{Double. Penalties for top rule curve to constrain final level.
#' @param until_convergence Binary. \code{TRUE} to repeat cycles until convergence of water values or
 attending the limit.}
}
\value{
\item{watervalues}{A \code{dplyr::tibble()} with multiple columns and detailed results.}
\item{aggregated_results}{A \code{dplyr::tibble()} with multiple columns and summarized results.}
}
\description{
Compute Bellman values and water values with dynamic programming based on reward functions computed with \code{get_Reward()}.
Mode information about this function in \code{vignette("grid_Matrix-parameters")}.
}

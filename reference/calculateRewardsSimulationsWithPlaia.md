# Compute reward function for `node` with plaia implementation. The reward function of each week and each year is evaluated on `nb_simulations` controls. Called for each area of `getBellmanValuesSequentialMultiStockWithPlaia()`. If they are several areas, the trajectories of the other storage are fixed on their `optimal_trend`.

Compute reward function for `node` with plaia implementation. The reward
function of each week and each year is evaluated on `nb_simulations`
controls. Called for each area of
[`getBellmanValuesSequentialMultiStockWithPlaia()`](https://rte-antares-rpackage.github.io/antaresWaterValues/reference/getBellmanValuesSequentialMultiStockWithPlaia.md).
If they are several areas, the trajectories of the other storage are
fixed on their `optimal_trend`.

## Usage

``` r
calculateRewardsSimulationsWithPlaia(
  node,
  list_areas,
  list_efficiency,
  opts,
  mcyears,
  nb_simulations,
  optimal_traj,
  list_max_hydro_weekly
)
```

## Arguments

- node:

  Character. Name of the area where the reward is computed

- list_areas:

  Vector of areas concerned by simulations.

- list_efficiency:

  List of double. Efficiency for each area generated by
  [`getPumpEfficiency()`](https://rte-antares-rpackage.github.io/antaresWaterValues/reference/getPumpEfficiency.md).

- opts:

  List of study parameters returned by the function
  `antaresRead::setSimulationPath(simulation="input")` in input mode.

- mcyears:

  Vector of integer. Monte Carlo years used to compute water values.

- nb_simulations:

  Number of controls to simulate

- optimal_traj:

  Data frame containing optimal trajectory for all areas

- list_max_hydro_weekly:

  List of data.frame. Generated by
  [`get_max_hydro()`](https://rte-antares-rpackage.github.io/antaresWaterValues/reference/get_max_hydro.md)
  for each area.

## Value

a `data_frame` containing the rewards returned by the function
[`get_Reward()`](https://rte-antares-rpackage.github.io/antaresWaterValues/reference/get_Reward.md)
